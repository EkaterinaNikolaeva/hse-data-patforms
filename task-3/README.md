# Автоматизированное развертывание YARN

## Установка

1. Установите git и python

```
sudo apt install git -y
```

```
sudo apt install python3 -y
```

2. Склонируйте репозиторий командой

```
git clone https://github.com/EkaterinaNikolaeva/hse-data-patforms.git
```

3. Перейдите в директорию проекта

```
cd hse-data-patforms/task-3/
```

4. Для установки необходимых зависимостей выполните

```
python3 main.py prepare
```

Эта команда установит ansible, sshpass.

5. Для развертывания HDFS и YARN:

* Замените `<pass>` в файле `inventory.ini` на реальный пароль
* При необходимости измените переменные базы данных в `inventory.ini`:
  - `db_user` - пользователь базы данных (по умолчанию: hive)
  - `db_password` - пароль пользователя (по умолчанию: hiveMegaPass)
  - `db_name` - имя базы данных (по умолчанию: metastore)

* Для развертывания hdfs выполните:

```
python3 main.py hdfs
```

Эта команда запустит playbook `run_hdfs.yml`

* Для разертывания YARN выполните:

```
python3 main.py yarn
```

Эта команда запустит playbook `run_yarn.yml`

* Для развертывания Hive выполните:

```
python3 main.py hive
```

Эта команда запустит playbook `run_hive.yml`

6. Для тестирования функциональности выполните

**Для тестирования MapReduce:**
```
python3 main.py yarn-test
```

Эта команда запустит playbook `yarn_test/test_mapreduce.yml` который:
- Скопирует тестовые файлы из папки `yarn_test/` (mapper.py, reducer.py, file1.txt, file2.txt, file3.txt) на NameNode
- Загрузит тестовые файлы в HDFS
- Запустит MapReduce задачу подсчета слов
- Покажет результаты и сравнит с ожидаемыми

**Для тестирования Hive:**
```
python3 main.py hive-test
```

Эта команда запустит playbook `hive_test/test_beeline.yml` который:
- Проверит доступность HiveServer2 на порту 5433
- Создаст тестовую базу данных и таблицу
- Выполнит тестовые SQL-запросы через Beeline
- Проверит корректность работы Hive
- Очистит тестовые данные

7. Для очистки примененных изменений примените

```
python3 main.py clean
```

Эта команда запустит playbook `cleanup.yml`

**Дополнительные флаги для команды clean:**

```
python3 main.py clean --keep-archives
```
Сохраняет скачанные архивы (Hadoop, Hive) для повторного использования

## Тестовые файлы

### Тестовые файлы MapReduce

В папке `yarn_test/` включены следующие тестовые файлы для проверки MapReduce:

### Скрипты MapReduce:
- `yarn_test/mapper.py` - скрипт для разбиения текста на слова
- `yarn_test/reducer.py` - скрипт для подсчета частоты слов

### Тестовые данные:
- `yarn_test/file1.txt` - "hello yarn hello hadoop"
- `yarn_test/file2.txt` - "mapreduce python test"  
- `yarn_test/file3.txt` - "yarn cluster working"

### Playbook для тестирования:
- `yarn_test/test_mapreduce.yml` - Ansible playbook для автоматического тестирования

### Ожидаемые результаты:
```
cluster	1
hadoop	2
hello	2
mapreduce	1
python	1
test	1
working	1
yarn	2
```

### Тестовые файлы Hive

В папке `hive_test/` включены следующие тестовые файлы для проверки Hive:

### Playbook для тестирования Hive:
- `hive_test/test_beeline.yml` - Ansible playbook для автоматического тестирования Hive через Beeline

### Процесс тестирования Hive:
1. **Проверка доступности HiveServer2** - ожидание запуска сервера на порту 5433
2. **Создание тестового SQL-скрипта** - генерация скрипта с тестовыми операциями:
   - Создание тестовой базы данных `hive_test`
   - Создание тестовой таблицы `test` с полями `id` и `status`
   - Вставка тестовых данных
   - Выполнение SELECT-запроса для проверки данных
   - Удаление тестовых объектов
3. **Выполнение тестов** - запуск SQL-скрипта через Beeline
4. **Проверка результатов** - валидация успешного выполнения операций
5. **Очистка** - удаление временных файлов

### Ожидаемые результаты тестирования Hive:
- Успешное подключение к HiveServer2
- Создание базы данных и таблицы
- Корректная вставка и выборка данных
- Успешная очистка тестовых объектов

## Проверка работоспособности

1. Для удобного доступа к интерфейсу можно выполнить команду:

```
ssh -L 9870:192.168.1.7:9870 -L 8088:192.168.1.7:8088 -L 19888:192.168.1.7:19888 team@<ip>
```
Тогда в браузере можно будет открыть:
* `localhost:9870` — Web-интерфейс NameNode (HDFS)
* `localhost:8088` — Web-интерфейс ResourceManager (YARN)
* `localhost:19888` — Web-интерфейс HistoryServer для MapReduce



## Процесс развёртывания

### HDFS

Playbook `run_hdfs.yml` выполняет полное развёртывание Hadoop HDFS кластера в несколько этапов:

#### Этап 1: Подготовка пользователей и SSH-доступа
- **Создание пользователя hadoop** - системный пользователь для работы Hadoop на всех узлах
- **Настройка SSH-ключей** - генерация ключей и настройка беспарольного доступа между узлами кластера
- **Обновление /etc/hosts** - конфигурация сетевых имен узлов через шаблон `hosts.j2`

#### Этап 2: Загрузка Hadoop дистрибутива
- **Загрузка архива Hadoop 3.4.0** - выполняется только на jump-узле для экономии трафика
- **Сохранение в директорию /home/team/downloads/** - временное хранение дистрибутива

#### Этап 3: Распространение и установка Hadoop
- **Копирование архива** - распространение Hadoop со jump-узла на все узлы кластера
- **Распаковка дистрибутива** - извлечение в `/home/hadoop/hadoop-3.4.0/`
- **Настройка прав доступа** - рекурсивное назначение владельца hadoop для всех файлов
- **Конфигурация Hadoop** - применение шаблонов конфигурационных файлов:
  - `hadoop-env.sh` - переменные окружения Hadoop
  - `core-site.xml` - основные настройки кластера
  - `hdfs-site.xml` - параметры HDFS
  - `workers` - список DataNode узлов

#### Этап 4: Создание файловых систем
- **Директория NameNode** - создается только на NameNode узлах для метаданных (`/home/hadoop/hadoop_data/namenode`)
- **Директория DataNode** - создается на всех узлах для хранения данных (`/home/hadoop/hadoop_data/datanode`)

#### Этап 5. Инициализация переменных окружения

- Инициализируем переменные окружения HADOOP_HOME, JAVA_HOME

#### Этап 6: Инициализация и запуск HDFS
- **Форматирование HDFS** - инициализация файловой системы (выполняется один раз при первом запуске)
- **Запуск сервисов** - старт демонов NameNode, DataNode и Secondary NameNode

### YARN

#### Этап 1: Копирование конфигурационных файлов

* `mapred-site.xml.j2` задает параметры работы MapReduce на кластере

* `yarn-site.xml.j2` - конфиг-файл YARN

#### Этап 2: Запуск YARN

* Запускаем ResourceManager и NodeManager

* Запускаем MapReduce History Server

### Hive

#### Этап 1: Установка PostgreSQL на DataNode

* **Установка PostgreSQL** - установка сервера PostgreSQL на втором DataNode (dn-01)
* **Создание пользователя hive** - создание пользователя с паролем для доступа к базе данных
* **Создание базы данных metastore** - создание базы данных для хранения метаданных Hive
* **Настройка доступа** - предоставление прав доступа пользователю hive к базе данных metastore
* **Конфигурация аутентификации** - добавление записи в pg_hba.conf для доступа с NameNode
* **Конфигурация PostgreSQL** - настройка прослушивания на адресе DataNode

#### Этап 2: Установка PostgreSQL клиента на NameNode

* **Установка клиента** - установка PostgreSQL клиента для подключения к базе данных

#### Этап 3: Загрузка Hive на jump-узле

* **Загрузка Hive 4.0.0-alpha-2** - скачивание дистрибутива Apache Hive в директорию `/home/team/downloads/`

#### Этап 4: Установка Hive на NameNode

* **Копирование архива** - распространение Hive с jump-узла на NameNode
* **Распаковка архива** - извлечение Hive в домашнюю директорию пользователя hadoop
* **Загрузка JDBC драйвера** - скачивание PostgreSQL JDBC драйвера в lib директорию Hive
* **Конфигурация Hive** - создание файла hive-site.xml с настройками подключения к PostgreSQL

#### Этап 5: Настройка переменных окружения

* **HIVE_HOME** - путь к установленному Hive
* **HIVE_CONF_DIR** - путь к конфигурационным файлам Hive
* **HIVE_AUX_JARS_PATH** - путь к дополнительным JAR файлам
* **PATH** - добавление Hive в переменную PATH
* **Использование blockinfile** - управляемые блоки переменных окружения

#### Этап 6: Настройка HDFS для Hive

* **Создание директорий** - создание `/tmp` и `/user/hive/warehouse` в HDFS
* **Настройка прав доступа** - установка групповых прав записи для директорий

#### Этап 7: Инициализация схемы Hive

* **Создание схемы** - инициализация схемы базы данных для Hive metastore с использованием `initOrUpgradeSchema`

#### Этап 8: Запуск сервисов Hive

* **Hive Metastore** - запуск сервиса метаданных в фоновом режиме
* **HiveServer2** - запуск сервера Hive с отключенной авторизацией в фоновом режиме

## Процесс очистки

Playbook `cleanup.yml` выполняет полное удаление Hadoop HDFS кластера, YARN, Hive и всех связанных компонентов в несколько этапов:

**Управление удалением файлов:**
- По умолчанию удаляются все скачанные архивы и данные
- Флаг `--keep-archives` сохраняет архивы Hadoop и Hive для повторного использования

#### Этап 1: Остановка сервисов Hive
- **Остановка HiveServer2** - завершение работы сервера Hive
- **Остановка Hive Metastore** - завершение работы сервиса метаданных

#### Этап 2: Остановка сервисов HDFS
- **Остановка HDFS** - выполнение скрипта `stop-dfs.sh` для корректного завершения работы:
  - NameNode
  - DataNode 
  - Secondary NameNode

#### Этап 2: Принудительное завершение оставшихся процессов
- **Завершение Java-процессов** - принудительное завершение всех Java-процессов пользователя hadoop
- **Завершение всех процессов hadoop** - полная очистка всех процессов, принадлежащих пользователю hadoop

#### Этап 3: Удаление файлов Hive
- **Удаление дистрибутива Hive** - полное удаление директории `/home/hadoop/apache-hive-4.0.0-alpha-2-bin/` со всеми:
  - Исполняемыми файлами
  - Конфигурационными файлами
  - Логами и временными файлами
- **Удаление архива Hive** - удаление скачанного архива Hive с jump-узла (если не используется флаг `--keep-archives`)

#### Этап 4: Удаление PostgreSQL
- **Остановка PostgreSQL** - завершение работы сервера базы данных
- **Удаление пакетов PostgreSQL** - полное удаление PostgreSQL с очисткой конфигурации
- **Удаление данных PostgreSQL** - удаление всех данных и конфигурации базы данных
- **Удаление PostgreSQL клиента** - удаление клиентских пакетов с NameNode

#### Этап 5: Удаление файлов Hadoop
- **Удаление дистрибутива Hadoop** - полное удаление директории `/home/hadoop/hadoop-3.4.0/` со всеми:
  - Исполняемыми файлами
  - Конфигурационными файлами
  - Логами и временными файлами
- **Удаление архива Hadoop** - удаление скачанного архива Hadoop с jump-узла (если не используется флаг `--keep-archives`)
- **Удаление домашней директории** - удаление всей домашней директории пользователя hadoop включая:
  - SSH-ключи
  - Данные HDFS (`hadoop_data`)
  - Временные файлы

#### Этап 6: Удаление системных записей
- **Удаление пользователя hadoop** - полное удаление пользователя c домашней директорией
- **Удаление группы hadoop** - удаление системной группы
